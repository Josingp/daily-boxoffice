import os
import json
import requests
import datetime
import time
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache

# --- [ì„¤ì •] ---
DAILY_FILE = "public/daily_data.json"
ARCHIVE_DIR = "public/archive"
MANUAL_FILE = "manual_data.json"
KOBIS_API_KEY = os.environ.get("KOBIS_API_KEY")

# --- [ìœ í‹¸: ë°ì´í„° ë¡œë“œ] ---
def load_manual_data():
    """ìˆ˜ë™ ë°ì´í„°(í¬ìŠ¤í„°/ì œì‘ë¹„ ë“±)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(MANUAL_FILE):
        try:
            with open(MANUAL_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

def load_existing_data():
    """
    ê¸°ì¡´ ë°ì´í„° íŒŒì¼ì—ì„œ 'ìƒì„¸ì •ë³´(detail)'ì™€ 'ê³¼ê±° íŠ¸ë Œë“œ(trend)'ë¥¼ ëª¨ë‘ ë¡œë“œí•©ë‹ˆë‹¤.
    ì´ë¥¼ í†µí•´ API ì¤‘ë³µ í˜¸ì¶œì„ ë°©ì§€í•˜ê³  ë°ì´í„°ë¥¼ ëˆ„ì í•©ë‹ˆë‹¤.
    """
    detail_cache = {}
    trend_cache = {}
    
    if os.path.exists(DAILY_FILE):
        try:
            with open(DAILY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                movies_list = data.get("movies", [])
                
                # moviesê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ (êµ¬ë²„ì „ í˜¸í™˜)
                if isinstance(movies_list, dict): 
                    movies_list = [] # êµ¬ì¡°ê°€ ë‹¤ë¥´ë©´ ì´ˆê¸°í™”
                
                for movie in movies_list:
                    movie_cd = movie.get("movieCd")
                    if not movie_cd: continue
                    
                    # ìƒì„¸ì •ë³´ ìºì‹±
                    if movie.get("detail"):
                        detail_cache[movie_cd] = movie["detail"]
                    
                    # íŠ¸ë Œë“œ ë°ì´í„° ìºì‹±
                    if movie.get("trend"):
                        trend_map = {}
                        for t in movie["trend"]:
                            if "date" in t:
                                trend_map[t["date"]] = t
                        trend_cache[movie_cd] = trend_map
                        
        except Exception as e:
            print(f"[Cache] Failed to load existing file: {e}")
            
    manual = load_manual_data()
    return detail_cache, trend_cache, manual

# --- [í•µì‹¬: API í˜¸ì¶œ] ---
@lru_cache(maxsize=None)
def fetch_api_list(target_dt):
    """íŠ¹ì • ë‚ ì§œì˜ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì¤‘ë³µ í˜¸ì¶œ ì‹œ ìºì‹œ ì‚¬ìš©)."""
    url = "https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json"
    try:
        res = requests.get(f"{url}?key={KOBIS_API_KEY}&targetDt={target_dt}&itemPerPage=10", timeout=5)
        return res.json().get("boxOfficeResult", {}).get("dailyBoxOfficeList", [])
    except: return []

def fetch_movie_detail(movie_cd, movie_nm, cache, manual_data):
    """ì˜í™” ìƒì„¸ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ìºì‹œ -> API -> ìˆ˜ë™ë°ì´í„° ë³‘í•©)."""
    info = {}
    
    # 1. ìºì‹œ(ê¸°ì¡´ íŒŒì¼) í™•ì¸
    if movie_cd in cache and cache[movie_cd]:
        info = cache[movie_cd]
    else:
        # 2. API í˜¸ì¶œ (ì—†ìœ¼ë©´ 3íšŒ ì¬ì‹œë„)
        url = "https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json"
        for attempt in range(3):
            try:
                res = requests.get(f"{url}?key={KOBIS_API_KEY}&movieCd={movie_cd}", timeout=5)
                data = res.json().get("movieInfoResult", {}).get("movieInfo", {})
                if data and "movieNm" in data:
                    info = data
                    break
                raise Exception("Empty data")
            except:
                time.sleep((attempt + 1) * 2)

    # 3. ìˆ˜ë™ ë°ì´í„°(í¬ìŠ¤í„°, ì œì‘ë¹„) ë³‘í•©
    if movie_nm:
        clean_title = movie_nm.strip().replace(" ", "")
        for m_title, m_info in manual_data.items():
            if m_title.strip().replace(" ", "") == clean_title:
                info.update(m_info)
                break
            
    return info

def main():
    print("Starting Daily Update (Incremental Mode)...")
    
    if not KOBIS_API_KEY: 
        print("ğŸš¨ Error: KOBIS API Key is missing.")
        return

    # 1. ë‚ ì§œ ì„¤ì • (ì–´ì œ ê¸°ì¤€)
    today = datetime.datetime.now()
    yesterday = (today - datetime.timedelta(days=1)).strftime("%Y%m%d")
    print(f"Target Date: {yesterday}")

    # 2. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¦ë¶„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ í•„ìˆ˜)
    detail_cache, trend_cache, manual_data = load_existing_data()
    
    # 3. ì–´ì œ ì ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    target_list = fetch_api_list(yesterday)
    
    if not target_list:
        print(f"âš ï¸ No box office data found for {yesterday}.")
        # ë°ì´í„°ê°€ ì—†ì–´ë„ ê¸°ì¡´ ë°ì´í„° ìœ ì§€ë¥¼ ìœ„í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì§„í–‰í•˜ì§€ ì•Šê³  ì¢…ë£Œí•˜ê±°ë‚˜
        # ì´ì „ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.
        return

    final_movies = []

    # 4. ì˜í™”ë³„ ë°ì´í„° ì²˜ë¦¬
    # API ë¶€í•˜ë¥¼ ê³ ë ¤í•´ ì›Œì»¤ ìˆ˜ ì¡°ì ˆ
    with ThreadPoolExecutor(max_workers=3) as executor:
        for movie in target_list:
            movie_cd = movie['movieCd']
            movie_nm = movie['movieNm']
            
            # ê°œë´‰ì¼ ì²˜ë¦¬
            open_dt_raw = movie.get('openDt', '').replace("-", "")
            
            print(f"Processing: {movie_nm} ({movie_cd})...")
            
            # --- íŠ¸ë Œë“œ(ê³¼ê±° ìˆœìœ„) ë¶„ì„ ---
            date_list = []
            start_date = None
            
            # A. ìˆ˜ì§‘ ì‹œì‘ì¼ ê²°ì • (ê°œë´‰ì¼ vs 30ì¼ ì „)
            if open_dt_raw:
                try: 
                    start_date = datetime.datetime.strptime(open_dt_raw, "%Y%m%d")
                    # ë¯¸ë˜ ê°œë´‰ì‘ì´ê±°ë‚˜ ë°ì´í„° ì˜¤ë¥˜ì¸ ê²½ìš°, ìµœê·¼ 7ì¼ë¡œ ì•ˆì „ì¥ì¹˜
                    limit_date = datetime.datetime.strptime(yesterday, "%Y%m%d")
                    if start_date > limit_date:
                         start_date = limit_date - datetime.timedelta(days=7)
                except: pass
            
            if not start_date:
                start_date = today - datetime.timedelta(days=30)
            
            # B. ê°œë´‰ì¼ ~ ì–´ì œê¹Œì§€ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            curr = start_date
            end_date_obj = datetime.datetime.strptime(yesterday, "%Y%m%d")
            
            # ë¬´í•œë£¨í”„ ë°©ì§€ ì•ˆì „ì¥ì¹˜ (ìµœëŒ€ 3ë…„ì¹˜ë§Œ)
            safety_count = 0
            while curr <= end_date_obj and safety_count < 1100:
                date_list.append(curr.strftime("%Y%m%d"))
                curr += datetime.timedelta(days=1)
                safety_count += 1
            
            # C. ì´ë¯¸ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„° í™•ì¸ (Incremental Fetch)
            existing_movie_trend = trend_cache.get(movie_cd, {})
            dates_to_fetch = [d for d in date_list if d not in existing_movie_trend]
            
            if dates_to_fetch:
                print(f"   -> Fetching {len(dates_to_fetch)} missing days for {movie_nm}...")
            
            # D. ëˆ„ë½ëœ ë‚ ì§œë§Œ API í˜¸ì¶œ (ë³‘ë ¬ ì²˜ë¦¬)
            trend_futures = {executor.submit(fetch_api_list, d): d for d in dates_to_fetch}
            
            for f in trend_futures:
                d_key = trend_futures[f]
                try:
                    d_data = f.result()
                    found = next((m for m in d_data if m['movieCd'] == movie_cd), None)
                    if found:
                        # ìƒˆë¡œ ê°€ì ¸ì˜¨ ë°ì´í„° ì €ì¥ (dateDisplay í¬í•¨)
                        existing_movie_trend[d_key] = {
                            "date": d_key,
                            "dateDisplay": f"{d_key[4:6]}/{d_key[6:8]}",
                            "audiCnt": int(found['audiCnt']),
                            "salesAmt": int(found['salesAmt']),
                            "scrnCnt": int(found['scrnCnt']),
                            "showCnt": int(found['showCnt'])
                        }
                    else:
                        # í•´ë‹¹ ë‚ ì§œì— ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ê¸°ë¡ì´ ì—†ìŒ (ìˆœìœ„ ë°–) -> 0ìœ¼ë¡œ ì±„ìš°ì§€ ì•Šê³  ìŠ¤í‚µ (ê·¸ë˜í”„ ì—°ê²°ì„ ìœ„í•´)
                        pass
                except Exception as e: 
                    print(f"Error fetching {d_key}: {e}")
            
            # E. ìµœì¢… íŠ¸ë Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° ì •ë ¬
            final_trend_list = list(existing_movie_trend.values())
            final_trend_list.sort(key=lambda x: x['date'])
            movie['trend'] = final_trend_list

            # ì „ì¼ ëŒ€ë¹„ ì¦ê° ê³„ì‚° (trend ë°ì´í„° ê¸°ì¤€)
            if len(final_trend_list) >= 2:
                last = final_trend_list[-1]
                prev = final_trend_list[-2]
                movie['scrnInten'] = last['scrnCnt'] - prev['scrnCnt']
                movie['showInten'] = last['showCnt'] - prev['showCnt']
            else:
                movie['scrnInten'] = 0
                movie['showInten'] = 0
            
            # --- ìƒì„¸ì •ë³´ ë³‘í•© ---
            movie['detail'] = fetch_movie_detail(movie_cd, movie_nm, detail_cache, manual_data)
            final_movies.append(movie)

    # 5. ìˆœìœ„ ì •ë ¬ ë° ì €ì¥
    final_movies.sort(key=lambda x: int(x['rank']))

    if not os.path.exists("public"): os.makedirs("public")
    final_data = {"date": yesterday, "movies": final_movies}
    
    # [ì €ì¥ 1] ë©”ì¸ íŒŒì¼ (ì›¹ì‚¬ì´íŠ¸ìš©)
    with open(DAILY_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    # [ì €ì¥ 2] ì•„ì¹´ì´ë¸Œ (ë‚ ì§œë³„ ë°±ì—…)
    year = yesterday[:4]
    month = yesterday[4:6]
    archive_path = os.path.join(ARCHIVE_DIR, year, month)
    os.makedirs(archive_path, exist_ok=True)
    
    archive_file = os.path.join(archive_path, f"{yesterday}.json")
    with open(archive_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Successfully saved {len(final_movies)} movies with FULL history.")

if __name__ == "__main__":
    main()

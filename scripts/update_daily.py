import os
import json
import requests
import datetime
import time
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache

# --- [ì„¤ì •] ---
DAILY_FILE = "public/daily_data.json"
ARCHIVE_DIR = "public/archive"
MANUAL_FILE = "manual_data.json"
KOBIS_API_KEY = os.environ.get("KOBIS_API_KEY")

# --- [ìœ í‹¸: ë°ì´í„° ë¡œë“œ] ---
def load_manual_data():
    """ìˆ˜ë™ ë°ì´í„°(í¬ìŠ¤í„°/ì œì‘ë¹„ ë“±)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(MANUAL_FILE):
        try:
            with open(MANUAL_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

def load_existing_details():
    """ê¸°ì¡´ ë°ì´í„°ì—ì„œ ìƒì„¸ì •ë³´(detail)ë§Œ ìºì‹±í•˜ì—¬ API í˜¸ì¶œì„ ì¤„ì…ë‹ˆë‹¤."""
    cache = {}
    if os.path.exists(DAILY_FILE):
        try:
            with open(DAILY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for movie in data.get("movies", []):
                    if movie.get("detail") and movie.get("movieCd"):
                        cache[movie["movieCd"]] = movie["detail"]
        except Exception as e:
            print(f"[Cache] Failed to load existing file: {e}")
            
    manual = load_manual_data()
    return cache, manual

# --- [í•µì‹¬: API í˜¸ì¶œ ìµœì í™”] ---
@lru_cache(maxsize=None)
def fetch_api_list(target_dt):
    """íŠ¹ì • ë‚ ì§œì˜ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì¤‘ë³µ í˜¸ì¶œ ì‹œ ìºì‹œ ì‚¬ìš©)."""
    url = "https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json"
    try:
        # print(f"API Call for {target_dt}") # ë””ë²„ê¹… í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
        res = requests.get(f"{url}?key={KOBIS_API_KEY}&targetDt={target_dt}&itemPerPage=10", timeout=5)
        return res.json().get("boxOfficeResult", {}).get("dailyBoxOfficeList", [])
    except: return []

def fetch_movie_detail(movie_cd, movie_nm, cache, manual_data):
    """ì˜í™” ìƒì„¸ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ìºì‹œ -> API -> ìˆ˜ë™ë°ì´í„° ë³‘í•©)."""
    info = {}
    
    # 1. ìºì‹œ(ê¸°ì¡´ íŒŒì¼) í™•ì¸
    if movie_cd in cache and cache[movie_cd]:
        info = cache[movie_cd]
    else:
        # 2. API í˜¸ì¶œ (ì—†ìœ¼ë©´ 3íšŒ ì¬ì‹œë„)
        url = "https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json"
        for attempt in range(3):
            try:
                res = requests.get(f"{url}?key={KOBIS_API_KEY}&movieCd={movie_cd}", timeout=5)
                data = res.json().get("movieInfoResult", {}).get("movieInfo", {})
                if data and "movieNm" in data:
                    info = data
                    break
                raise Exception("Empty data")
            except:
                time.sleep((attempt + 1) * 2)

    # 3. ìˆ˜ë™ ë°ì´í„°(í¬ìŠ¤í„°, ì œì‘ë¹„) ë³‘í•©
    clean_title = movie_nm.strip().replace(" ", "")
    for m_title, m_info in manual_data.items():
        if m_title.strip().replace(" ", "") == clean_title:
            info.update(m_info)
            break
            
    return info

def main():
    print("Starting Daily Update...")
    
    if not KOBIS_API_KEY: 
        print("ğŸš¨ Error: KOBIS API Key is missing.")
        return

    # 1. ë‚ ì§œ ì„¤ì • (ì–´ì œ ê¸°ì¤€)
    today = datetime.datetime.now()
    yesterday = (today - datetime.timedelta(days=1)).strftime("%Y%m%d")
    print(f"Target Date: {yesterday}")

    # 2. ë°ì´í„° ì¤€ë¹„
    detail_cache, manual_data = load_existing_details()
    target_list = fetch_api_list(yesterday)
    
    if not target_list:
        print(f"âš ï¸ No box office data found for {yesterday}.")
        return

    final_movies = []

    # 3. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    with ThreadPoolExecutor(max_workers=3) as executor:
        for movie in target_list:
            movie_cd = movie['movieCd']
            movie_nm = movie['movieNm']
            open_dt = movie['openDt'].replace("-", "") if movie['openDt'] else ""
            
            print(f"Processing: {movie_nm} ({movie_cd})...")
            
            # --- íŠ¸ë Œë“œ(ê³¼ê±° ìˆœìœ„) ë¶„ì„ ---
            date_list = []
            if open_dt and open_dt <= yesterday:
                try: curr = datetime.datetime.strptime(open_dt, "%Y%m%d")
                except: curr = datetime.datetime.strptime((today - datetime.timedelta(days=30)).strftime("%Y%m%d"), "%Y%m%d")
            else:
                curr = datetime.datetime.strptime((today - datetime.timedelta(days=30)).strftime("%Y%m%d"), "%Y%m%d")
            
            end_date = datetime.datetime.strptime(yesterday, "%Y%m%d")
            while curr <= end_date:
                date_list.append(curr.strftime("%Y%m%d"))
                curr += datetime.timedelta(days=1)
            
            # API ê³¼ë¶€í•˜ ë°©ì§€: ìµœëŒ€ 90ì¼ì¹˜ë§Œ ì¡°íšŒ
            if len(date_list) > 90: date_list = date_list[-90:]
            
            trend_data = []
            trend_futures = {executor.submit(fetch_api_list, d): d for d in date_list}
            
            for f in trend_futures:
                d_key = trend_futures[f]
                try:
                    d_data = f.result()
                    found = next((m for m in d_data if m['movieCd'] == movie_cd), None)
                    if found:
                        trend_data.append({
                            "date": d_key,
                            "audiCnt": int(found['audiCnt']),
                            "salesAmt": int(found['salesAmt']),
                            "scrnCnt": int(found['scrnCnt']),
                            "showCnt": int(found['showCnt'])
                        })
                except: pass
            
            trend_data.sort(key=lambda x: x['date'])
            movie['trend'] = trend_data

            # ì „ì¼ ëŒ€ë¹„ ì¦ê° ê³„ì‚°
            if len(trend_data) >= 2:
                movie['scrnInten'] = trend_data[-1]['scrnCnt'] - trend_data[-2]['scrnCnt']
                movie['showInten'] = trend_data[-1]['showCnt'] - trend_data[-2]['showCnt']
            else:
                movie['scrnInten'] = 0
                movie['showInten'] = 0
            
            # --- ìƒì„¸ì •ë³´ ë³‘í•© ---
            movie['detail'] = fetch_movie_detail(movie_cd, movie_nm, detail_cache, manual_data)
            final_movies.append(movie)

    # 4. ìˆœìœ„ ì •ë ¬ ë° ì €ì¥
    final_movies.sort(key=lambda x: int(x['rank']))

    if not os.path.exists("public"): os.makedirs("public")
    final_data = {"date": yesterday, "movies": final_movies}
    
    # [ì €ì¥ 1] ë©”ì¸ íŒŒì¼ (ì›¹ì‚¬ì´íŠ¸ìš©)
    with open(DAILY_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    # [ì €ì¥ 2] ì•„ì¹´ì´ë¸Œ (ë°ì´í„° ë³´ì¡´ìš©: public/archive/2026/01/20260123.json)
    year = yesterday[:4]
    month = yesterday[4:6]
    archive_path = os.path.join(ARCHIVE_DIR, year, month)
    os.makedirs(archive_path, exist_ok=True)
    
    archive_file = os.path.join(archive_path, f"{yesterday}.json")
    with open(archive_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Successfully saved {len(final_movies)} movies.")
    print(f"ğŸ“‚ Archived at: {archive_file}")

if __name__ == "__main__":
    main()
